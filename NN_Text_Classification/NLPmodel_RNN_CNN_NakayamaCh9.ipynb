{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN(多対1), RNN(1対1), Bidirectional RNN, CNNによるテキスト分類\n",
    "- 各ニューラルネットワークのアーキテクチャとそれらを用いた分類問題への対処の理解\n",
    "- Embedding構造の理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "- [機械学習・深層学習による自然言語処理入門 ~scikit-learnとTensorFlowを使った実践プログラミング](https://www.amazon.co.jp/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%BB%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%81%AB%E3%82%88%E3%82%8B%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%85%A5%E9%96%80-scikit-learn%E3%81%A8TensorFlow%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E5%AE%9F%E8%B7%B5%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-Compass-Data-Science/dp/4839966605/)\n",
    "- [09_text_classification.ipynb](https://colab.research.google.com/drive/1iAE2OUx7nFZzyrasJMYGf8fxd_fO80t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "#import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, SimpleRNN, LSTM, Conv1D, GlobalMaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 250   # 1オブザベーション（トークン化されたtext）の最大長\n",
    "num_words = 40000    # ユニーク単語数上限\n",
    "num_label = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 642 ms, total: 13 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## データのロードとクリーニング、列選択（review_body、star_rating）\n",
    "\n",
    "def filter_by_ascii_rate(text, threshold=0.9):\n",
    "    ascii_letters = set(string.printable)\n",
    "    rate = sum(c in ascii_letters for c in text) / len(text)\n",
    "    return rate <= threshold\n",
    "\n",
    "def load_dataset(filename, n=5000, state=6):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "    # Converts multi-class to binary-class.\n",
    "    mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n",
    "    df = df[df.star_rating != 3]\n",
    "    df.star_rating = df.star_rating.map(mapping)\n",
    "\n",
    "    # extracts Japanese texts.\n",
    "    is_jp = df.review_body.apply(filter_by_ascii_rate)\n",
    "    df = df[is_jp]\n",
    "\n",
    "    # sampling.\n",
    "    df = df.sample(frac=1, random_state=state)  # shuffle\n",
    "    grouped = df.groupby('star_rating')\n",
    "    df = grouped.head(n=n)\n",
    "    return df.review_body.values, df.star_rating.values\n",
    "\n",
    "def clean_html(html, strip=False):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # タグ除去\n",
    "    text = soup.get_text(strip=strip)\n",
    "    return text\n",
    "\n",
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz'\n",
    "x, y = load_dataset(url)\n",
    "x = [clean_html(text, strip=True) for text in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>現在、地球温暖化の悪影響が、ここまで顕在化しているとは想像していませんでした。特に、このまま...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>このアクション映画ほど、男気を感じたものはあったのだろうか。シンプル構成で時間をたっぷりと使...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>このアプリを入れて以来、かなりお世話になりました。私の場合、PCで作成したデータや画像を出先...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>取り出してさっと撮影することが必要な旅行用に不可欠だと思います。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kindleで使用しています。複数のCloudが管理できたり、ワードやエクセルが使えたりと素...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating\n",
       "0  現在、地球温暖化の悪影響が、ここまで顕在化しているとは想像していませんでした。特に、このまま...            1\n",
       "1  このアクション映画ほど、男気を感じたものはあったのだろうか。シンプル構成で時間をたっぷりと使...            1\n",
       "2  このアプリを入れて以来、かなりお世話になりました。私の場合、PCで作成したデータや画像を出先...            0\n",
       "3                   取り出してさっと撮影することが必要な旅行用に不可欠だと思います。            1\n",
       "4  Kindleで使用しています。複数のCloudが管理できたり、ワードやエクセルが使えたりと素...            1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 作成されたデータ\n",
    "df = pd.DataFrame({'review_body':x, 'star_rating':y})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['現在、地球温暖化の悪影響が、ここまで顕在化しているとは想像していませんでした。特に、このまま海面温度が上昇を続けると、早晩、南極・北極の氷が大規模に溶けることによって相当の範囲の陸地が海に没し、十億人単位での難民が発生するという事実には、本当に衝撃を受けました。ある人が、「人間は地球にすくう癌細胞のようである。増殖・破壊を続け、最終的には自らも寄生先の死によって滅ぶ運命にある」と言っていたことを思い出しました。一方、主人公であるゴア氏が、聴衆が数十人〜数百人程度の世界中の教室・会議場をまわって危機を訴えるという、地道な「草の根」の活動にも大変感銘を受けました。個人的には、ゴア氏には、ブッシュ氏との大統領戦における、「賢いが傲慢で冷徹」というイメージが強かったのですが、およそそんなことはない（＝きっと、ブッシュ陣営のネガティブ・キャンペーンの影響を愚かにも受けていたのでしょう）、信念を持ち、実行力が伴った、特筆すべき政治家であることも分かりました。温暖化の危機、ゴア氏ほかの活動家・学者の行動に対する不明を恥じると共に、自らもCO2ゼロ化に向けて早速行動したいと思いました。なお、当作品は、語られる事象のすべてが具体的かつ客観的に科学的根拠に支えられており、ドキュメンタリーとしても秀逸だと思います。是非ご覧になってみて下さい。お奨めします。',\n",
       " 'このアクション映画ほど、男気を感じたものはあったのだろうか。シンプル構成で時間をたっぷりと使った中身のあるアクション映画です。劇中、鉄斧を持った闇のサイコ集団（敵）が出てくるんですがスタローンがこれでもかと、鉄拳制裁っ！するあたりはまさに圧巻の連続です。シンプルな映画ですが、家族で見ててハラハラドキドキします。また、この頃の映画って何か麻薬的な中毒性がありますよね。何度も映画の世界に引きずり込まれてしまいます。最近のアクション映画に物足りなさを感じている方、ぜひこのスタローンアクションを見て日々の疲れきった人生にスパイスを与えましょう。']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 227 ms, total: 2min 6s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# トークン化\n",
    "t = Tokenizer(wakati=True)\n",
    "\n",
    "x = [' '.join(t.tokenize(text)) for text in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['現在 、 地球 温暖 化 の 悪影響 が 、 ここ まで 顕在 化 し て いる と は 想像 し て い ませ ん でし た 。 特に 、 この まま 海面 温度 が 上昇 を 続ける と 、 早晩 、 南極 ・ 北極 の 氷 が 大 規模 に 溶ける こと によって 相当 の 範囲 の 陸地 が 海 に 没し 、 十 億 人 単位 で の 難民 が 発生 する という 事実 に は 、 本当に 衝撃 を 受け まし た 。 ある 人 が 、 「 人間 は 地球 に すくう 癌 細胞 の よう で ある 。 増殖 ・ 破壊 を 続け 、 最終 的 に は 自ら も 寄生 先 の 死 によって 滅ぶ 運命 に ある 」 と 言っ て い た こと を 思い出し まし た 。 一方 、 主人公 で ある ゴア 氏 が 、 聴衆 が 数 十 人 〜 数 百 人 程度 の 世界中 の 教室 ・ 会議 場 を まわっ て 危機 を 訴える という 、 地道 な 「 草の根 」 の 活動 に も 大変 感銘 を 受け まし た 。 個人 的 に は 、 ゴア 氏 に は 、 ブッシュ 氏 と の 大統領 戦 における 、 「 賢い が 傲慢 で 冷徹 」 という イメージ が 強かっ た の です が 、 およそ そんな こと は ない （ ＝ きっと 、 ブッシュ 陣営 の ネガティブ ・ キャンペーン の 影響 を 愚か に も 受け て い た の でしょ う ） 、 信念 を 持ち 、 実行 力 が 伴っ た 、 特筆 す べき 政治 家 で ある こと も 分かり まし た 。 温暖 化 の 危機 、 ゴア 氏 ほか の 活動 家 ・ 学者 の 行動 に対する 不明 を 恥じる と共に 、 自ら も CO 2 ゼロ 化 に 向け て 早速 行動 し たい と 思い まし た 。 なお 、 当 作品 は 、 語ら れる 事象 の すべて が 具体 的 かつ 客観 的 に 科学 的 根拠 に 支え られ て おり 、 ドキュメンタリー として も 秀逸 だ と 思い ます 。 是非 ご覧 に なっ て み て 下さい 。 お 奨め し ます 。',\n",
       " 'この アクション 映画 ほど 、 男気 を 感じ た もの は あっ た の だろ う か 。 シンプル 構成 で 時間 を たっぷり と 使っ た 中身 の ある アクション 映画 です 。 劇 中 、 鉄 斧 を 持っ た 闇 の サイコ 集団 （ 敵 ） が 出 て くる ん です が スタローン が これ でも か と 、 鉄拳 制 裁っ ！ する あたり は まさに 圧巻 の 連続 です 。 シンプル な 映画 です が 、 家族 で 見 て て ハラハラ ドキドキ し ます 。 また 、 この 頃 の 映画 って 何 か 麻薬 的 な 中毒 性 が あり ます よ ね 。 何 度 も 映画 の 世界 に 引きずり込ま れ て しまい ます 。 最近 の アクション 映画 に 物足りな さ を 感じ て いる 方 、 ぜひ この スタローンアクション を 見 て 日々 の 疲れ きっ た 人生 に スパイス を 与え ましょ う 。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000 8000 2000\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### tf.keras.preprocessing.text.Tokenizer\n",
    "- Text tokenization utility class.\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras_preprocessing.text.Tokenizer'>\n"
     ]
    }
   ],
   "source": [
    "test_texts = ['子ども たち に 見せ た ところ 、 もう 、 ページ を めくる たび に 面白い ねぇ という 喜び の 声 が 聞か れ まし た よ 。 今 の 子ども たち は 草原 を 通り抜け たり 、 川 を 渡っ たり など 、 お話 に 出 て くる よう な 体験 が あまり あり ませ ん 。 です から 、 この ポップアップ は ほんとに イメージ が 膨らん で くる ので いい なぁ と 思い ます 。 ぜひ 、 お 薦め です 。',\n",
    "         '１ 枚 目 は 、 完全 に 演奏 は レイジ 、 メロディー は クリス と 、 水 と 油 みたい な 感じ で 違和感 たっぷり でし た が 、 ２ 枚 目 に なっ て 、 かなり クリス 色 の 強い バンド に 生まれ変わっ た 感じ が し ます 。 要は サウンド ガーデン っぽく なっ た 。 ただ 、 出し てる 音 は レイジ そのもの な ので 、 クリス の ボーカル スタイル に は 少し オケ が 寂しく 感じ て しまう 。 ７ 曲 目 くらい 、 ギター に も ボーカル に も エフェクター を 効か せ て 派手 に し て やっと クリスコーネル 節 が 生き て くる 。 スーパーアンノウン を 超える ほど の アルバム を 期待 し てる 私 として は また 肩透かし を 食らい まし た （ そりゃ 当人 たち は そんな 音楽 を する つもり は 無い の でしょ う が ） 冷静 に 、 サウンド ガーデン 、 レイジアゲインストザマシーン それぞれ の 一番 好き な アルバム と 比較 し て 、 それぞれ より も かっこいい と は 言え ませ ん 。 ただし 、 １ 枚 目 より ２ 枚 目 が 凄く 良い の は 確か な ので 、 ３ 枚 目 に 期待 を 込め て 、 この 作品 を 噛み締める という の が 、 レイジファン 、 クリス ファン の 楽しみ 方 な の かも しれ ませ ん 。 ８ 曲 目 とか １ ０ 曲 目 に 、 新しい 可能 性 を 感じ た 私 は そう し まし た 。']\n",
    "\n",
    "tknzr = tf.keras.preprocessing.text.Tokenizer(num_words=100, oov_token='<UNK>')   # インプットの次元(単語の種類)を100とする場合\n",
    "print(type(tknzr))\n",
    "tknzr.fit_on_texts(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<UNK>',\n",
       " 2: '、',\n",
       " 3: 'に',\n",
       " 4: 'は',\n",
       " 5: 'を',\n",
       " 6: 'の',\n",
       " 7: '。',\n",
       " 8: 'が',\n",
       " 9: 'た',\n",
       " 10: 'て',\n",
       " 11: '目',\n",
       " 12: 'な',\n",
       " 13: 'と',\n",
       " 14: '枚',\n",
       " 15: 'し',\n",
       " 16: 'クリス',\n",
       " 17: '感じ',\n",
       " 18: 'たち',\n",
       " 19: 'まし',\n",
       " 20: 'くる',\n",
       " 21: 'ませ',\n",
       " 22: 'ん',\n",
       " 23: 'ので',\n",
       " 24: '１',\n",
       " 25: '曲',\n",
       " 26: 'も',\n",
       " 27: '子ども',\n",
       " 28: 'という',\n",
       " 29: 'たり',\n",
       " 30: 'です',\n",
       " 31: 'この',\n",
       " 32: 'で',\n",
       " 33: 'ます',\n",
       " 34: 'レイジ',\n",
       " 35: '２',\n",
       " 36: 'なっ',\n",
       " 37: 'サウンド',\n",
       " 38: 'ガーデン',\n",
       " 39: 'てる',\n",
       " 40: 'ボーカル',\n",
       " 41: 'アルバム',\n",
       " 42: '期待',\n",
       " 43: '私',\n",
       " 44: 'それぞれ',\n",
       " 45: 'より',\n",
       " 46: '見せ',\n",
       " 47: 'ところ',\n",
       " 48: 'もう',\n",
       " 49: 'ページ',\n",
       " 50: 'めくる',\n",
       " 51: 'たび',\n",
       " 52: '面白い',\n",
       " 53: 'ねぇ',\n",
       " 54: '喜び',\n",
       " 55: '声',\n",
       " 56: '聞か',\n",
       " 57: 'れ',\n",
       " 58: 'よ',\n",
       " 59: '今',\n",
       " 60: '草原',\n",
       " 61: '通り抜け',\n",
       " 62: '川',\n",
       " 63: '渡っ',\n",
       " 64: 'など',\n",
       " 65: 'お話',\n",
       " 66: '出',\n",
       " 67: 'よう',\n",
       " 68: '体験',\n",
       " 69: 'あまり',\n",
       " 70: 'あり',\n",
       " 71: 'から',\n",
       " 72: 'ポップアップ',\n",
       " 73: 'ほんとに',\n",
       " 74: 'イメージ',\n",
       " 75: '膨らん',\n",
       " 76: 'いい',\n",
       " 77: 'なぁ',\n",
       " 78: '思い',\n",
       " 79: 'ぜひ',\n",
       " 80: 'お',\n",
       " 81: '薦め',\n",
       " 82: '完全',\n",
       " 83: '演奏',\n",
       " 84: 'メロディー',\n",
       " 85: '水',\n",
       " 86: '油',\n",
       " 87: 'みたい',\n",
       " 88: '違和感',\n",
       " 89: 'たっぷり',\n",
       " 90: 'でし',\n",
       " 91: 'かなり',\n",
       " 92: '色',\n",
       " 93: '強い',\n",
       " 94: 'バンド',\n",
       " 95: '生まれ変わっ',\n",
       " 96: '要は',\n",
       " 97: 'っぽく',\n",
       " 98: 'ただ',\n",
       " 99: '出し',\n",
       " 100: '音',\n",
       " 101: 'そのもの',\n",
       " 102: 'スタイル',\n",
       " 103: '少し',\n",
       " 104: 'オケ',\n",
       " 105: '寂しく',\n",
       " 106: 'しまう',\n",
       " 107: '７',\n",
       " 108: 'くらい',\n",
       " 109: 'ギター',\n",
       " 110: 'エフェクター',\n",
       " 111: '効か',\n",
       " 112: 'せ',\n",
       " 113: '派手',\n",
       " 114: 'やっと',\n",
       " 115: 'クリスコーネル',\n",
       " 116: '節',\n",
       " 117: '生き',\n",
       " 118: 'スーパーアンノウン',\n",
       " 119: '超える',\n",
       " 120: 'ほど',\n",
       " 121: 'として',\n",
       " 122: 'また',\n",
       " 123: '肩透かし',\n",
       " 124: '食らい',\n",
       " 125: '（',\n",
       " 126: 'そりゃ',\n",
       " 127: '当人',\n",
       " 128: 'そんな',\n",
       " 129: '音楽',\n",
       " 130: 'する',\n",
       " 131: 'つもり',\n",
       " 132: '無い',\n",
       " 133: 'でしょ',\n",
       " 134: 'う',\n",
       " 135: '）',\n",
       " 136: '冷静',\n",
       " 137: 'レイジアゲインストザマシーン',\n",
       " 138: '一番',\n",
       " 139: '好き',\n",
       " 140: '比較',\n",
       " 141: 'かっこいい',\n",
       " 142: '言え',\n",
       " 143: 'ただし',\n",
       " 144: '凄く',\n",
       " 145: '良い',\n",
       " 146: '確か',\n",
       " 147: '３',\n",
       " 148: '込め',\n",
       " 149: '作品',\n",
       " 150: '噛み締める',\n",
       " 151: 'レイジファン',\n",
       " 152: 'ファン',\n",
       " 153: '楽しみ',\n",
       " 154: '方',\n",
       " 155: 'かも',\n",
       " 156: 'しれ',\n",
       " 157: '８',\n",
       " 158: 'とか',\n",
       " 159: '０',\n",
       " 160: '新しい',\n",
       " 161: '可能',\n",
       " 162: '性',\n",
       " 163: 'そう'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index : 単語\n",
    "# 学習したデータは、全部で162語\n",
    "# texts_to_sequencesを呼ぶ場合、num_words=100を上限として、それより後のindexの単語、もしくは存在しない単語は1: '<UNK>'に振り分けられる\n",
    "tknzr.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[68, 17, 1, 62, 85], [25, 27, 1, 1, 99, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforms each text in texts to a sequence of integers.\n",
    "tknzr.texts_to_sequences(['体験 感じ 山 川 水', '曲 子ども abc 性 出し 音'])\n",
    "\n",
    "# 1は<UNK>\n",
    "# index=100の'音'は1となっている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x7fea208c8ca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_words=40000(インプットのベクトル次元)を上限とする辞書（indexと単語の対比）の作成と、単語ベースの学習データをindexベースへ変換\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, oov_token='<UNK>')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)    # 学習データから辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK>  :  1\n",
      "の  :  2\n",
      "、  :  3\n",
      "。  :  4\n",
      "が  :  5\n",
      "は  :  6\n",
      "に  :  7\n",
      "て  :  8\n",
      "た  :  9\n",
      "を  :  10\n",
      "で  :  11\n"
     ]
    }
   ],
   "source": [
    "#tokenizer.word_index      # 辞書を表示すると長くなるので\n",
    "i = 0\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    print(key, ' : ' ,value)\n",
    "    i += 1\n",
    "    if i>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データ（x_train）に存在した総単語数\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['何一つ 本棚 に データー が 入っ て い ない 。 どう すれ ば 入る の か も 分から ない 。',\n",
       " '他 の かた の レビュー に も ある 様 に 十分 に 面白かっ た 。 カーペンター 版 ほど で は ない に せよ 何 度 も 観 返し たく なる 。 こう なっ たら ノルウェー と アメリカ の 生存 者 と で 続編 作っ ちゃっ て 欲しい な 。 思いっきり 絶望 的 な ラスト を 観 て み たい w']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(x_train)    # 単語ベースの学習データをindexベースへ変換\n",
    "x_test = tokenizer.texts_to_sequences(x_test)      # 単語ベースのテストデータをindexベースへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6981,\n",
       "  13752,\n",
       "  7,\n",
       "  8239,\n",
       "  5,\n",
       "  293,\n",
       "  8,\n",
       "  23,\n",
       "  17,\n",
       "  4,\n",
       "  185,\n",
       "  559,\n",
       "  59,\n",
       "  840,\n",
       "  2,\n",
       "  20,\n",
       "  13,\n",
       "  526,\n",
       "  17,\n",
       "  4]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=maxlen, truncating='post', padding='post')        # これが学習に用いられる最終的なデータフォーマット\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen, truncating='post', padding='post')\n",
    "# textがmaxlen=250より長い場合、後ろを打ち切る\n",
    "# textがmaxlen=250より短い場合、後ろへパディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6981, 13752,     7,  8239,     5,   293,     8,    23,    17,\n",
       "            4,   185,   559,    59,   840,     2,    20,    13,   526,\n",
       "           17,     4,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 250) (2000, 250)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### tf.keras.preprocessing.sequence.pad_sequences\n",
    "- Pads sequences to the same length.\n",
    "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0, 68, 17,  1, 62],\n",
       "       [ 0,  0,  0,  0, 25, 27,  1,  1, 99,  1]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 例\n",
    "pad_sequences([[68, 17, 1, 62], [25, 27, 1, 1, 99, 1]], maxlen=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Embedding\n",
    "- 正の整数（インデックス）を固定次元の密ベクトルに変換します．\n",
    "- https://keras.io/ja/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([[0, 1, 2, 3, 4],[5, 1, 2, 3, 6],[9, 9, 0, 1, 7]])\n",
    "vocab_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 3)             30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model = Sequential()\n",
    "test_model.add(Embedding(input_dim=vocab_size, output_dim=3, input_length=10))    # 3次元のEmbedding\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.03483588,  0.02110745, -0.04418308],\n",
       "        [ 0.03699956,  0.04006091, -0.0232033 ],\n",
       "        [-0.01917415, -0.04058304,  0.02055681],\n",
       "        [-0.00866901,  0.04949265, -0.04987855],\n",
       "        [ 0.0324736 , -0.04071965, -0.0340901 ]],\n",
       "\n",
       "       [[-0.04668638, -0.01326425, -0.04543719],\n",
       "        [ 0.03699956,  0.04006091, -0.0232033 ],\n",
       "        [-0.01917415, -0.04058304,  0.02055681],\n",
       "        [-0.00866901,  0.04949265, -0.04987855],\n",
       "        [-0.00274274, -0.01532656,  0.01879683]],\n",
       "\n",
       "       [[ 0.03845752, -0.01631987, -0.01848371],\n",
       "        [ 0.03845752, -0.01631987, -0.01848371],\n",
       "        [ 0.03483588,  0.02110745, -0.04418308],\n",
       "        [ 0.03699956,  0.04006091, -0.0232033 ],\n",
       "        [ 0.00013831, -0.02045832,  0.02474436]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)  ->  (3, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape, ' -> ', test_model.predict(test_input).shape)\n",
    "\n",
    "# 3テキスト、各5単語 -> 各単語をoutput_dim=3次元に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 300)          12000000  \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 12,040,302\n",
      "Trainable params: 12,040,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "#inp = Input(shape=(None,), name='input')\n",
    "inp = Input(shape=(maxlen,), name='input')    # maxlen:文長（パディング込み単語数）\n",
    "out = Embedding(input_dim=num_words, output_dim=300, mask_zero=True, trainable=True, name='embedding')(inp) # 各単語を300次元のベクトルに変換\n",
    "out = SimpleRNN(units=100, return_sequences=False, name='rnn')(out)\n",
    "out = Dense(units=num_label, activation='softmax')(out)\n",
    "model_rnn = Model(inputs=inp, outputs=out)\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 250)\n",
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.617645  , 0.382355  ],\n",
       "       [0.42916092, 0.57083905],\n",
       "       [0.4959029 , 0.5040971 ]], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-out確認\n",
    "print(x_test[:3].shape)\n",
    "\n",
    "print(model_rnn(x_test[:3]).shape)\n",
    "model_rnn(x_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンパイル\n",
    "model_rnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 11s 208ms/step - loss: 0.6890 - acc: 0.5403 - val_loss: 0.6494 - val_acc: 0.6306\n",
      "INFO:tensorflow:Assets written to: models/rnn/assets\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 0.4140 - acc: 0.8610 - val_loss: 0.7027 - val_acc: 0.6438\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 10s 207ms/step - loss: 0.0530 - acc: 0.9889 - val_loss: 0.8681 - val_acc: 0.6100\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 11s 213ms/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.9437 - val_acc: 0.6131\n",
      "CPU times: user 4min 12s, sys: 42.9 s, total: 4min 55s\n",
      "Wall time: 43.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea72d13280>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 学習\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "model_path = 'models/rnn'\n",
    "\n",
    "model_rnn.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3),\n",
    "        ModelCheckpoint(model_path, save_best_only=True)\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 250)\n",
      "---------- sample input data ----------\n",
      "[2004    2  245    5 1106   16    5    3    1  109   74  319  361 7036\n",
      "   14    8 4756   17   12   53   68  509    7   88   14   28    9    4\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "--------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9139584 , 0.08604164],\n",
       "       [0.06404482, 0.9359552 ],\n",
       "       [0.162492  , 0.83750796],\n",
       "       [0.00578979, 0.99421024],\n",
       "       [0.97406524, 0.02593472]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "print(x_test.shape)\n",
    "print('---------- sample input data ----------')\n",
    "print(x_test[0])\n",
    "print('--------------------------------------------')\n",
    "\n",
    "y_pred = model_rnn.predict(x_test)\n",
    "y_pred[:5]\n",
    "# 結果：[prob(0), prob(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8065\n",
      "precision: 0.7909\n",
      "recall: 0.8193\n",
      "f1: 0.8048\n"
     ]
    }
   ],
   "source": [
    "# 精度評価\n",
    "print('accuracy: {:.4f}'.format(accuracy_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('precision: {:.4f}'.format(precision_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('recall: {:.4f}'.format(recall_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('f1: {:.4f}'.format(f1_score(y_pred.argmax(axis=1), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN（1対1 アーキテクチャ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 300)          12000000  \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, 250, 100)          40100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 12,040,302\n",
      "Trainable params: 12,040,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "#inp = Input(shape=(None,), name='input')\n",
    "inp = Input(shape=(maxlen,), name='input')    # maxlen:文長（パディング込み単語数）\n",
    "out = Embedding(input_dim=num_words, output_dim=300, mask_zero=True, trainable=True, name='embedding')(inp) # 各単語を300次元のベクトルに変換\n",
    "out = SimpleRNN(units=100, return_sequences=True, name='rnn')(out)   # 文で１つの出力でなく、文の各単語で１つの出力（各100次元）\n",
    "out = GlobalMaxPooling1D()(out)    # 単語単位次元を文単位次元へ集約\n",
    "out = Dense(units=num_label, activation='softmax')(out)\n",
    "model_rnn1 = Model(inputs=inp, outputs=out)\n",
    "model_rnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンパイル\n",
    "model_rnn1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 12s 235ms/step - loss: 0.7627 - acc: 0.5235 - val_loss: 0.6563 - val_acc: 0.6550\n",
      "INFO:tensorflow:Assets written to: models/rnn1/assets\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 11s 227ms/step - loss: 0.5754 - acc: 0.7911 - val_loss: 0.7487 - val_acc: 0.6212\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 12s 237ms/step - loss: 0.4260 - acc: 0.8364 - val_loss: 0.5648 - val_acc: 0.7169\n",
      "INFO:tensorflow:Assets written to: models/rnn1/assets\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 12s 233ms/step - loss: 0.2765 - acc: 0.9331 - val_loss: 0.5352 - val_acc: 0.7312\n",
      "INFO:tensorflow:Assets written to: models/rnn1/assets\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 12s 234ms/step - loss: 0.1672 - acc: 0.9652 - val_loss: 0.5809 - val_acc: 0.7212\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 0.0923 - acc: 0.9866 - val_loss: 0.6133 - val_acc: 0.7219\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 12s 230ms/step - loss: 0.0466 - acc: 0.9956 - val_loss: 0.6333 - val_acc: 0.7188\n",
      "CPU times: user 8min 5s, sys: 1min 24s, total: 9min 29s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea81718370>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 学習\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "model_path = 'models/rnn1'\n",
    "\n",
    "model_rnn1.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3),\n",
    "        ModelCheckpoint(model_path, save_best_only=True)\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9970542 , 0.00294579],\n",
       "       [0.04774555, 0.95225453],\n",
       "       [0.07028291, 0.9297171 ],\n",
       "       [0.1441599 , 0.85584015],\n",
       "       [0.3739004 , 0.6260996 ]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "y_pred = model_rnn1.predict(x_test)\n",
    "y_pred[:5]\n",
    "# 結果：[prob(0), prob(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7360\n",
      "precision: 0.7998\n",
      "recall: 0.7123\n",
      "f1: 0.7535\n"
     ]
    }
   ],
   "source": [
    "# 精度評価\n",
    "print('accuracy: {:.4f}'.format(accuracy_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('precision: {:.4f}'.format(precision_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('recall: {:.4f}'.format(recall_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('f1: {:.4f}'.format(f1_score(y_pred.argmax(axis=1), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### SimpleRNN、return_sequences=True/Falseの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 100)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 1      #バッチサイズ\n",
    "text_len = 10    # 文長（単語数）\n",
    "emb_size = 100 # Enbedding size\n",
    "data = np.random.randn(batch, text_len, emb_size)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       "array([[-0.6500587 , -0.24879389, -0.6879822 , -0.99083513]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn1 = SimpleRNN(units=4, return_sequences=False)     # 多対１ アーキテクチャ\n",
    "\n",
    "print(rnn1(data).shape)\n",
    "rnn1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 4), dtype=float32, numpy=\n",
       "array([[[ 0.76792735,  0.97077435,  0.95259386,  0.64597696],\n",
       "        [ 0.6241702 ,  0.97440255, -0.3481571 ,  0.8570433 ],\n",
       "        [ 0.6964981 ,  0.99988705,  0.77277637,  0.98311377],\n",
       "        [ 0.8903857 ,  0.64649814,  0.59279853,  0.9962734 ],\n",
       "        [ 0.80222005,  0.9726263 ,  0.9834009 , -0.9951626 ],\n",
       "        [ 0.9782352 ,  0.9983396 ,  0.9591549 ,  0.55979997],\n",
       "        [ 0.9923823 , -0.76988775, -0.75557476, -0.73030835],\n",
       "        [ 0.3630569 ,  0.88714206,  0.5512719 , -0.89675605],\n",
       "        [-0.9412261 ,  0.95178545,  0.975192  ,  0.6974632 ],\n",
       "        [ 0.9130821 , -0.6712648 ,  0.3056602 ,  0.92335725]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn2 = SimpleRNN(units=4, return_sequences=True)     # １対１ アーキテクチャ\n",
    "\n",
    "print(rnn2(data).shape)      # 文長のまま出力される\n",
    "rnn2(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 300)          12000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 12,080,602\n",
      "Trainable params: 12,080,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "#inp = Input(shape=(None,), name='input')\n",
    "inp = Input(shape=(maxlen,), name='input')\n",
    "out = Embedding(input_dim=num_words, output_dim=300, mask_zero=True, trainable=True, name='embedding')(inp) # 各単語を300次元のベクトルに変換\n",
    "out = Bidirectional(SimpleRNN(units=100, return_sequences=False, name='rnn'))(out)\n",
    "out = Dense(units=num_label, activation='softmax')(out)\n",
    "model_rnn2 = Model(inputs=inp, outputs=out)\n",
    "model_rnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 250)\n",
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.4475823 , 0.55241776],\n",
       "       [0.54116607, 0.45883384],\n",
       "       [0.4581206 , 0.54187936]], dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-out確認\n",
    "print(x_test[:3].shape)\n",
    "\n",
    "print(model_rnn2(x_test[:3]).shape)\n",
    "model_rnn2(x_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンパイル\n",
    "model_rnn2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 15s 283ms/step - loss: 0.6553 - acc: 0.6119 - val_loss: 0.5039 - val_acc: 0.7638\n",
      "INFO:tensorflow:Assets written to: models/rnn2/assets\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 14s 285ms/step - loss: 0.2432 - acc: 0.9094 - val_loss: 0.5317 - val_acc: 0.7613\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 14s 284ms/step - loss: 0.0314 - acc: 0.9964 - val_loss: 0.6424 - val_acc: 0.7444\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 14s 275ms/step - loss: 0.0056 - acc: 0.9998 - val_loss: 0.5831 - val_acc: 0.7906\n",
      "CPU times: user 7min 13s, sys: 1min 10s, total: 8min 23s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea53d730a0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 学習\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "model_path = 'models/rnn2'\n",
    "\n",
    "model_rnn2.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3),\n",
    "        ModelCheckpoint(model_path, save_best_only=True)\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.963963  , 0.03603706],\n",
       "       [0.06148687, 0.93851316],\n",
       "       [0.00653922, 0.9934608 ],\n",
       "       [0.06518713, 0.9348129 ],\n",
       "       [0.8471621 , 0.1528379 ]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "y_pred = model_rnn2.predict(x_test)\n",
    "y_pred[:5]\n",
    "# 結果：[prob(0), prob(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7955\n",
      "precision: 0.8305\n",
      "recall: 0.7788\n",
      "f1: 0.8038\n"
     ]
    }
   ],
   "source": [
    "# 精度評価\n",
    "print('accuracy: {:.4f}'.format(accuracy_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('precision: {:.4f}'.format(precision_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('recall: {:.4f}'.format(recall_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('f1: {:.4f}'.format(f1_score(y_pred.argmax(axis=1), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 250, 300)          12000000  \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 248, 150)          135150    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 302       \n",
      "=================================================================\n",
      "Total params: 12,135,452\n",
      "Trainable params: 12,135,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "#inp = Input(shape=(None,), name='input')\n",
    "inp = Input(shape=(maxlen,), name='input')\n",
    "out = Embedding(input_dim=num_words, output_dim=300, mask_zero=False, trainable=True, name='embedding')(inp) # 各単語を300次元のベクトルに変換\n",
    "out = Conv1D(filters=150, kernel_size=3, padding='valid', activation='relu', strides=1)(out)\n",
    "out = GlobalMaxPooling1D()(out)    # 畳み込み後の文長（248）を1次元へMax Pooling\n",
    "out = Dense(units=num_label, activation='softmax')(out)\n",
    "model_cnn = Model(inputs=inp, outputs=out)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンパイル\n",
    "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.6599 - acc: 0.6078 - val_loss: 0.5510 - val_acc: 0.7444\n",
      "INFO:tensorflow:Assets written to: models/cnn/assets\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 8s 169ms/step - loss: 0.4549 - acc: 0.8291 - val_loss: 0.4418 - val_acc: 0.8006\n",
      "INFO:tensorflow:Assets written to: models/cnn/assets\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.2608 - acc: 0.9230 - val_loss: 0.3881 - val_acc: 0.8256\n",
      "INFO:tensorflow:Assets written to: models/cnn/assets\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1234 - acc: 0.9784 - val_loss: 0.3837 - val_acc: 0.8388\n",
      "INFO:tensorflow:Assets written to: models/cnn/assets\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.0442 - acc: 0.9971 - val_loss: 0.3971 - val_acc: 0.8313\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0183 - acc: 0.9991 - val_loss: 0.4202 - val_acc: 0.8313\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4423 - val_acc: 0.8269\n",
      "CPU times: user 8min 57s, sys: 47.4 s, total: 9min 44s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea809c1c70>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 学習\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "model_path = 'models/cnn'\n",
    "\n",
    "model_cnn.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        EarlyStopping(patience=3),\n",
    "        ModelCheckpoint(model_path, save_best_only=True)\n",
    "    ],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96953636, 0.03046361],\n",
       "       [0.00173614, 0.9982639 ],\n",
       "       [0.00543109, 0.99456894],\n",
       "       [0.00274279, 0.9972573 ],\n",
       "       [0.96378964, 0.03621037]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測\n",
    "\n",
    "y_pred = model_cnn.predict(x_test)\n",
    "y_pred[:5]\n",
    "# 結果：[prob(0), prob(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8430\n",
      "precision: 0.8434\n",
      "recall: 0.8451\n",
      "f1: 0.8442\n"
     ]
    }
   ],
   "source": [
    "# 精度評価\n",
    "print('accuracy: {:.4f}'.format(accuracy_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('precision: {:.4f}'.format(precision_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('recall: {:.4f}'.format(recall_score(y_pred.argmax(axis=1), y_test)))\n",
    "print('f1: {:.4f}'.format(f1_score(y_pred.argmax(axis=1), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
