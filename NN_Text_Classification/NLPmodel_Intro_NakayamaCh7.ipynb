{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoWã‚’ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã¨ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡\n",
    "- BoWï¼ˆCount base One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã‚’ç”¨ã„ãŸã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‚è€ƒï¼š\n",
    "- [æ©Ÿæ¢°å­¦ç¿’ãƒ»æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªå‡¦ç†å…¥é–€ ~scikit-learnã¨TensorFlowã‚’ä½¿ã£ãŸå®Ÿè·µãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°](https://www.amazon.co.jp/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%BB%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%81%AB%E3%82%88%E3%82%8B%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%85%A5%E9%96%80-scikit-learn%E3%81%A8TensorFlow%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E5%AE%9F%E8%B7%B5%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-Compass-Data-Science/dp/4839966605/)\n",
    "- [07_simple_neural_network.ipynb](https://colab.research.google.com/drive/1GtFEsTloBKvDD6W_y2F2iNWgCUA7vvpO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 731 ms, total: 13.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€åˆ—é¸æŠï¼ˆreview_bodyã€star_ratingï¼‰\n",
    "\n",
    "def filter_by_ascii_rate(text, threshold=0.9):\n",
    "    ascii_letters = set(string.printable)\n",
    "    rate = sum(c in ascii_letters for c in text) / len(text)\n",
    "    return rate <= threshold\n",
    "\n",
    "def load_dataset(filename, n=5000, state=6):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "    # Converts multi-class to binary-class.\n",
    "    mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n",
    "    df = df[df.star_rating != 3]\n",
    "    df.star_rating = df.star_rating.map(mapping)\n",
    "\n",
    "    # extracts Japanese texts.\n",
    "    is_jp = df.review_body.apply(filter_by_ascii_rate)\n",
    "    df = df[is_jp]\n",
    "\n",
    "    # sampling.\n",
    "    df = df.sample(frac=1, random_state=state)  # shuffle\n",
    "    grouped = df.groupby('star_rating')\n",
    "    df = grouped.head(n=n)\n",
    "    return df.review_body.values, df.star_rating.values\n",
    "\n",
    "def clean_html(html, strip=False):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # ã‚¿ã‚°é™¤å»\n",
    "    text = soup.get_text(strip=strip)\n",
    "    return text\n",
    "\n",
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz'\n",
    "x, y = load_dataset(url)\n",
    "x = [clean_html(text, strip=True) for text in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ç¾åœ¨ã€åœ°çƒæ¸©æš–åŒ–ã®æ‚ªå½±éŸ¿ãŒã€ã“ã“ã¾ã§é¡•åœ¨åŒ–ã—ã¦ã„ã‚‹ã¨ã¯æƒ³åƒã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚ç‰¹ã«ã€ã“ã®ã¾ã¾...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã“ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ˜ ç”»ã»ã©ã€ç”·æ°—ã‚’æ„Ÿã˜ãŸã‚‚ã®ã¯ã‚ã£ãŸã®ã ã‚ã†ã‹ã€‚ã‚·ãƒ³ãƒ—ãƒ«æ§‹æˆã§æ™‚é–“ã‚’ãŸã£ã·ã‚Šã¨ä½¿...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ã“ã®ã‚¢ãƒ—ãƒªã‚’å…¥ã‚Œã¦ä»¥æ¥ã€ã‹ãªã‚ŠãŠä¸–è©±ã«ãªã‚Šã¾ã—ãŸã€‚ç§ã®å ´åˆã€PCã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚„ç”»åƒã‚’å‡ºå…ˆ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å–ã‚Šå‡ºã—ã¦ã•ã£ã¨æ’®å½±ã™ã‚‹ã“ã¨ãŒå¿…è¦ãªæ—…è¡Œç”¨ã«ä¸å¯æ¬ ã ã¨æ€ã„ã¾ã™ã€‚</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kindleã§ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚è¤‡æ•°ã®CloudãŒç®¡ç†ã§ããŸã‚Šã€ãƒ¯ãƒ¼ãƒ‰ã‚„ã‚¨ã‚¯ã‚»ãƒ«ãŒä½¿ãˆãŸã‚Šã¨ç´ ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating\n",
       "0  ç¾åœ¨ã€åœ°çƒæ¸©æš–åŒ–ã®æ‚ªå½±éŸ¿ãŒã€ã“ã“ã¾ã§é¡•åœ¨åŒ–ã—ã¦ã„ã‚‹ã¨ã¯æƒ³åƒã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚ç‰¹ã«ã€ã“ã®ã¾ã¾...            1\n",
       "1  ã“ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ˜ ç”»ã»ã©ã€ç”·æ°—ã‚’æ„Ÿã˜ãŸã‚‚ã®ã¯ã‚ã£ãŸã®ã ã‚ã†ã‹ã€‚ã‚·ãƒ³ãƒ—ãƒ«æ§‹æˆã§æ™‚é–“ã‚’ãŸã£ã·ã‚Šã¨ä½¿...            1\n",
       "2  ã“ã®ã‚¢ãƒ—ãƒªã‚’å…¥ã‚Œã¦ä»¥æ¥ã€ã‹ãªã‚ŠãŠä¸–è©±ã«ãªã‚Šã¾ã—ãŸã€‚ç§ã®å ´åˆã€PCã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚„ç”»åƒã‚’å‡ºå…ˆ...            0\n",
       "3                   å–ã‚Šå‡ºã—ã¦ã•ã£ã¨æ’®å½±ã™ã‚‹ã“ã¨ãŒå¿…è¦ãªæ—…è¡Œç”¨ã«ä¸å¯æ¬ ã ã¨æ€ã„ã¾ã™ã€‚            1\n",
       "4  Kindleã§ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚è¤‡æ•°ã®CloudãŒç®¡ç†ã§ããŸã‚Šã€ãƒ¯ãƒ¼ãƒ‰ã‚„ã‚¨ã‚¯ã‚»ãƒ«ãŒä½¿ãˆãŸã‚Šã¨ç´ ...            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿\n",
    "df = pd.DataFrame({'review_body':x, 'star_rating':y})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000 8000 2000\n"
     ]
    }
   ],
   "source": [
    "## Train/Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 552 ms, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## x_trainã€x_testã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "\n",
    "t = Tokenizer(wakati=True)\n",
    "\n",
    "def tokenize(text):\n",
    "    return t.tokenize(text)\n",
    "\n",
    "# Vectorizing dataset.\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize)  # Count Baseã®ãƒ™ã‚¯ã‚¿ãƒ©ã‚¤ã‚¶ãƒ¼\n",
    "x_train = vectorizer.fit_transform(x_train)    # Learn the vocabulary dictionary and return document-term matrix.\n",
    "x_test = vectorizer.transform(x_test)            # Transform documents to document-term matrix.\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 40980) (2000, 40980)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)    # 40980ãŒãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå˜èªæ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train    # ã“ã‚ŒãŒæœ€çµ‚çš„ã«æŠ•å…¥ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x03',\n",
       " '\\x08',\n",
       " '\\x1a',\n",
       " '\\x1a\\x1a',\n",
       " ' ',\n",
       " '  ',\n",
       " '   ',\n",
       " '    ',\n",
       " '     ',\n",
       " '      ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_trainã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸå˜èª\n",
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0003</th>\n",
       "      <th>\b</th>\n",
       "      <th>\u001a</th>\n",
       "      <th>\u001a\u001a</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th>ï¿£)ï¼¿</th>\n",
       "      <th>ï¿£;ï¼‰</th>\n",
       "      <th>ï¿£â–½ï¿£)</th>\n",
       "      <th>ï¿¥</th>\n",
       "      <th>ğŸ‘€</th>\n",
       "      <th>ğŸ’¢</th>\n",
       "      <th>ğŸ’¦</th>\n",
       "      <th>ğŸ˜</th>\n",
       "      <th>ğŸ˜¢</th>\n",
       "      <th>ó¾­›</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   \u0003  \b  \u001a  \u001a\u001a                                   ...  ï¿£)ï¼¿  ï¿£;ï¼‰  ï¿£â–½ï¿£)  ï¿¥  ğŸ‘€  ğŸ’¢  \\\n",
       "0  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "1  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "2  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "3  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "4  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "\n",
       "   ğŸ’¦  ğŸ˜  ğŸ˜¢  ó¾­›  \n",
       "0  0  0  0  0  \n",
       "1  0  0  0  0  \n",
       "2  0  0  0  0  \n",
       "3  0  0  0  0  \n",
       "4  0  0  0  0  \n",
       "\n",
       "[5 rows x 40980 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_trainã‚’DataFrameã§è¡¨ç¾ã™ã‚‹ã¨\n",
    "pd.DataFrame(x_train, columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40980 2\n"
     ]
    }
   ],
   "source": [
    "## Setting hyperparameters\n",
    "vocab_size = len(vectorizer.vocabulary_)   # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå˜èªæ•°  ->  ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã‚µã‚¤ã‚ºã¨ãªã‚‹\n",
    "label_size = len(set(y_train))                        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®æ°´æº–æ•°ï¼ˆï¼’å€¤ï¼‰\n",
    "print(vocab_size, label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f9d42ac2550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«å®šç¾©\n",
    "model = Sequential()\n",
    "model.add(Dense(units=16, activation='relu', input_shape=(vocab_size,)))\n",
    "model.add(Dense(units=label_size, activation='softmax'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                655696    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 655,730\n",
      "Trainable params: 655,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# 40980 -> 16 -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655696"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(40980+1) * 16   # input+bias * hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.5821 - accuracy: 0.7276 - val_loss: 0.4255 - val_accuracy: 0.8275\n",
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2221 - accuracy: 0.9316 - val_loss: 0.4170 - val_accuracy: 0.8381\n",
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1386 - accuracy: 0.9662 - val_loss: 0.4443 - val_accuracy: 0.8281\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0701 - accuracy: 0.9885 - val_loss: 0.4820 - val_accuracy: 0.8281\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0422 - accuracy: 0.9955 - val_loss: 0.5110 - val_accuracy: 0.8319\n",
      "CPU times: user 43.6 s, sys: 8.52 s, total: 52.1 s\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "save_path = '/tmp/model'\n",
    "log_dir = 'logs'\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "               EarlyStopping(monitor='val_loss', patience=3),\n",
    "               ModelCheckpoint(\n",
    "                   filepath=save_path,\n",
    "                   monitor='val_loss',\n",
    "                   save_best_only=True,\n",
    "                   mode='min'\n",
    "               ),\n",
    "               TensorBoard(log_dir=log_dir)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff451202fa0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ç²¾åº¦ï¼ˆAccuracyï¼‰\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy_score(y_pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17112611, 0.8288739 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## äºˆæ¸¬\n",
    "text = 'ã“ã®ã‚¢ãƒ—ãƒªè¶…æœ€é«˜ï¼'\n",
    "vec = vectorizer.transform([text])\n",
    "model.predict(vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
