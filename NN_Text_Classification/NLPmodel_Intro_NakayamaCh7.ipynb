{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoWをインプットとするニューラルネットワークによるテキスト分類\n",
    "- BoW（Count base One-Hotエンコーディング）を用いたシンプルな例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "- [機械学習・深層学習による自然言語処理入門 ~scikit-learnとTensorFlowを使った実践プログラミング](https://www.amazon.co.jp/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%BB%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%81%AB%E3%82%88%E3%82%8B%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86%E5%85%A5%E9%96%80-scikit-learn%E3%81%A8TensorFlow%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E5%AE%9F%E8%B7%B5%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-Compass-Data-Science/dp/4839966605/)\n",
    "- [07_simple_neural_network.ipynb](https://colab.research.google.com/drive/1GtFEsTloBKvDD6W_y2F2iNWgCUA7vvpO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import load_model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 731 ms, total: 13.1 s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## データのロードとクリーニング、列選択（review_body、star_rating）\n",
    "\n",
    "def filter_by_ascii_rate(text, threshold=0.9):\n",
    "    ascii_letters = set(string.printable)\n",
    "    rate = sum(c in ascii_letters for c in text) / len(text)\n",
    "    return rate <= threshold\n",
    "\n",
    "def load_dataset(filename, n=5000, state=6):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "    # Converts multi-class to binary-class.\n",
    "    mapping = {1: 0, 2: 0, 4: 1, 5: 1}\n",
    "    df = df[df.star_rating != 3]\n",
    "    df.star_rating = df.star_rating.map(mapping)\n",
    "\n",
    "    # extracts Japanese texts.\n",
    "    is_jp = df.review_body.apply(filter_by_ascii_rate)\n",
    "    df = df[is_jp]\n",
    "\n",
    "    # sampling.\n",
    "    df = df.sample(frac=1, random_state=state)  # shuffle\n",
    "    grouped = df.groupby('star_rating')\n",
    "    df = grouped.head(n=n)\n",
    "    return df.review_body.values, df.star_rating.values\n",
    "\n",
    "def clean_html(html, strip=False):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # タグ除去\n",
    "    text = soup.get_text(strip=strip)\n",
    "    return text\n",
    "\n",
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_multilingual_JP_v1_00.tsv.gz'\n",
    "x, y = load_dataset(url)\n",
    "x = [clean_html(text, strip=True) for text in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>現在、地球温暖化の悪影響が、ここまで顕在化しているとは想像していませんでした。特に、このまま...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>このアクション映画ほど、男気を感じたものはあったのだろうか。シンプル構成で時間をたっぷりと使...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>このアプリを入れて以来、かなりお世話になりました。私の場合、PCで作成したデータや画像を出先...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>取り出してさっと撮影することが必要な旅行用に不可欠だと思います。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kindleで使用しています。複数のCloudが管理できたり、ワードやエクセルが使えたりと素...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating\n",
       "0  現在、地球温暖化の悪影響が、ここまで顕在化しているとは想像していませんでした。特に、このまま...            1\n",
       "1  このアクション映画ほど、男気を感じたものはあったのだろうか。シンプル構成で時間をたっぷりと使...            1\n",
       "2  このアプリを入れて以来、かなりお世話になりました。私の場合、PCで作成したデータや画像を出先...            0\n",
       "3                   取り出してさっと撮影することが必要な旅行用に不可欠だと思います。            1\n",
       "4  Kindleで使用しています。複数のCloudが管理できたり、ワードやエクセルが使えたりと素...            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 作成されたデータ\n",
    "df = pd.DataFrame({'review_body':x, 'star_rating':y})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 2000 8000 2000\n"
     ]
    }
   ],
   "source": [
    "## Train/Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 552 ms, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## x_train、x_testのトークン化\n",
    "\n",
    "t = Tokenizer(wakati=True)\n",
    "\n",
    "def tokenize(text):\n",
    "    return t.tokenize(text)\n",
    "\n",
    "# Vectorizing dataset.\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize)  # Count Baseのベクタライザー\n",
    "x_train = vectorizer.fit_transform(x_train)    # Learn the vocabulary dictionary and return document-term matrix.\n",
    "x_test = vectorizer.transform(x_test)            # Transform documents to document-term matrix.\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 40980) (2000, 40980)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)    # 40980がトークン化されたユニークな単語数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train    # これが最終的に投入する学習データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x03',\n",
       " '\\x08',\n",
       " '\\x1a',\n",
       " '\\x1a\\x1a',\n",
       " ' ',\n",
       " '  ',\n",
       " '   ',\n",
       " '    ',\n",
       " '     ',\n",
       " '      ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_trainからトークン化された単語\n",
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\u0003</th>\n",
       "      <th>\b</th>\n",
       "      <th>\u001a</th>\n",
       "      <th>\u001a\u001a</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th>￣)＿</th>\n",
       "      <th>￣;）</th>\n",
       "      <th>￣▽￣)</th>\n",
       "      <th>￥</th>\n",
       "      <th>👀</th>\n",
       "      <th>💢</th>\n",
       "      <th>💦</th>\n",
       "      <th>😞</th>\n",
       "      <th>😢</th>\n",
       "      <th>󾭛</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   \u0003  \b  \u001a  \u001a\u001a                                   ...  ￣)＿  ￣;）  ￣▽￣)  ￥  👀  💢  \\\n",
       "0  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "1  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "2  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "3  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "4  0  0  0   0  0   0    0     0      0       0  ...    0    0     0  0  0  0   \n",
       "\n",
       "   💦  😞  😢  󾭛  \n",
       "0  0  0  0  0  \n",
       "1  0  0  0  0  \n",
       "2  0  0  0  0  \n",
       "3  0  0  0  0  \n",
       "4  0  0  0  0  \n",
       "\n",
       "[5 rows x 40980 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_trainをDataFrameで表現すると\n",
    "pd.DataFrame(x_train, columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40980 2\n"
     ]
    }
   ],
   "source": [
    "## Setting hyperparameters\n",
    "vocab_size = len(vectorizer.vocabulary_)   # ユニークな単語数  ->  モデルのインプットサイズとなる\n",
    "label_size = len(set(y_train))                        # ターゲットの水準数（２値）\n",
    "print(vocab_size, label_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f9d42ac2550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## モデル定義\n",
    "model = Sequential()\n",
    "model.add(Dense(units=16, activation='relu', input_shape=(vocab_size,)))\n",
    "model.add(Dense(units=label_size, activation='softmax'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                655696    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 655,730\n",
      "Trainable params: 655,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# 40980 -> 16 -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "655696"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(40980+1) * 16   # input+bias * hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.5821 - accuracy: 0.7276 - val_loss: 0.4255 - val_accuracy: 0.8275\n",
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2221 - accuracy: 0.9316 - val_loss: 0.4170 - val_accuracy: 0.8381\n",
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1386 - accuracy: 0.9662 - val_loss: 0.4443 - val_accuracy: 0.8281\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0701 - accuracy: 0.9885 - val_loss: 0.4820 - val_accuracy: 0.8281\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0422 - accuracy: 0.9955 - val_loss: 0.5110 - val_accuracy: 0.8319\n",
      "CPU times: user 43.6 s, sys: 8.52 s, total: 52.1 s\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## モデル学習\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "save_path = '/tmp/model'\n",
    "log_dir = 'logs'\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "               EarlyStopping(monitor='val_loss', patience=3),\n",
    "               ModelCheckpoint(\n",
    "                   filepath=save_path,\n",
    "                   monitor='val_loss',\n",
    "                   save_best_only=True,\n",
    "                   mode='min'\n",
    "               ),\n",
    "               TensorBoard(log_dir=log_dir)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff451202fa0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.831"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## テストデータに対する精度（Accuracy）\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy_score(y_pred.argmax(axis=1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17112611, 0.8288739 ]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 予測\n",
    "text = 'このアプリ超最高！'\n",
    "vec = vectorizer.transform([text])\n",
    "model.predict(vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
