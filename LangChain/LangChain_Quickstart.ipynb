{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19442d5b",
   "metadata": {},
   "source": [
    "## [LangChain](https://python.langchain.com/docs/get_started/introduction.html) [Quickstart](https://python.langchain.com/docs/get_started/quickstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bd135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.214'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3ad86",
   "metadata": {},
   "source": [
    "### [Environment setup](https://python.langchain.com/docs/get_started/quickstart#environment-setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fb942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "oai_key = open('../_secret/yuki-openaikey-20230613.txt', 'r').read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = oai_key\n",
    "#os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffe65c",
   "metadata": {},
   "source": [
    "### [LLMs](https://python.langchain.com/docs/get_started/quickstart#llms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503d3a7",
   "metadata": {},
   "source": [
    "API Reference: [langchain.llms](https://api.python.langchain.com/en/latest/modules/llms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "851823f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.湘南海風\n",
      "2.藤沢サーフアワー\n",
      "3.江ノ島サンセット\n",
      "4.鷹の谷インディアンサマー\n",
      "5.鎌倉ソーダブレイク\n",
      "6.葉山ロックンローラー\n",
      "7.三浦くだりサン\n",
      "8.横須賀サンセットストリーム\n",
      "9.平塚サンシャイン\n",
      "10.大船渡サーフライダー\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "llm_out = llm.predict(\"あなたはクラフトビールのブリュワリーのオーナーです。湘南をイメージしたクラフトビール名を複数考えて下さい\")\n",
    "print(llm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7751320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-davinci-003'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a08b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.api_resources.completion.Completion"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a074bba",
   "metadata": {},
   "source": [
    "### [Chat Models](https://python.langchain.com/docs/get_started/quickstart#chat-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2285b",
   "metadata": {},
   "source": [
    "API Reference: [langchain.chat_models](https://api.python.langchain.com/en/latest/modules/chat_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc957d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='私はプログラミングとビールを飲むことが大好きです。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "chat_out = chat.predict_messages(\n",
    "    [HumanMessage(content=\"この文章を日本語に翻訳して下さい。 I love programming and drinking beer.\")]\n",
    ")\n",
    "chat_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc78cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私はプログラミングとビールを飲むことが大好きです。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"この文章を日本語に翻訳して下さい。 I love programming and drinking beer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1e69fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181f5370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.api_resources.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d425e",
   "metadata": {},
   "source": [
    "### [Prompt templates](https://python.langchain.com/docs/get_started/quickstart#prompt-templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ee04a",
   "metadata": {},
   "source": [
    "API Reference: [langchain.prompts](https://api.python.langchain.com/en/latest/modules/prompts.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d551400",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c16fd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'クラフトジンを販売する店の名前を考えて下さい。'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{product}を販売する店の名前を考えて下さい。\")\n",
    "prompt.format(product=\"クラフトジン\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f61ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], output_parser=None, partial_variables={}, template='{product}を販売する店の名前を考えて下さい。', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d9f1bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n・クラフト・ティー・スター\\n・スタイリッシュ・クラフト\\n・クラフトティー・ハウス\\n・クラフティー・イースト\\n・クリエーション・ジン'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(prompt.format(product=\"クラフトジン\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50abe6",
   "metadata": {},
   "source": [
    "#### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "470fdf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='あなたはEnglishからJapaneseへの翻訳を実施する優秀なアシスタントです。', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming and playing surfing.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "template = \"あなたは{input_language}から{output_language}への翻訳を実施する優秀なアシスタントです。\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"Japanese\", text=\"I love programming and playing surfing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcbf38e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='あなたは{input_language}から{output_language}への翻訳を実施する優秀なアシスタントです。', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38bd1b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b68577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text', 'output_language', 'input_language'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='あなたは{input_language}から{output_language}への翻訳を実施する優秀なアシスタントです。', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "023bfda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='私はプログラミングとサーフィンが大好きです。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict_messages(\n",
    "    chat_prompt.format_messages(input_language=\"English\", output_language=\"Japanese\", text=\"I love programming and playing surfing.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aaf94c",
   "metadata": {},
   "source": [
    "### [Chains](https://python.langchain.com/docs/get_started/quickstart#chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f690cf",
   "metadata": {},
   "source": [
    "API Reference: [langchain.chains](https://api.python.langchain.com/en/latest/modules/chains.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe1fd85",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9251210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n・フレンチパグルショップ\\n・パグ・フレンチエル\\n・パグット・ド・フレンチ'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain.run(\"パグとフレンチブル\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c0bdf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-davinci-003'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "218fd1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['product'], output_parser=None, partial_variables={}, template='{product}を販売する店の名前を考えて下さい。', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319a6b2",
   "metadata": {},
   "source": [
    "#### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95da7d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私が俳優になることを決めた忘れられない瞬間でした。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "chain.run(input_language=\"English\", output_language=\"Japanese\", text=\"It was the unforgettable morment I decided to be an actor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9034157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "329b18ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text', 'output_language', 'input_language'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_language', 'output_language'], output_parser=None, partial_variables={}, template='あなたは{input_language}から{output_language}への翻訳を実施する優秀なアシスタントです。', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='{text}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56a662",
   "metadata": {},
   "source": [
    "### [Agents](https://python.langchain.com/docs/get_started/quickstart#agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405a28f",
   "metadata": {},
   "source": [
    "API Reference: [langchain.agents](https://api.python.langchain.com/en/latest/modules/agents.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a1ea8",
   "metadata": {},
   "source": [
    "[SerpApi](https://serpapi.com/)  \n",
    "[SerpApi python package install](https://pypi.org/project/google-search-results/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc3a8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_key = open('../_secret/yuki-serpapikey-20230625.txt', 'r').read()\n",
    "os.environ[\"SERPAPI_API_KEY\"] = serpapi_key\n",
    "#os.environ[\"SERPAPI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd68a928",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c29fea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the temperature in Tokyo yesterday and then calculate the square of that number.\n",
      "Action: Search\n",
      "Action Input: \"High temperature in Tokyo yesterday\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTokyo Weather History for the Previous 24 Hours ; 85 °F · 87 °F · 82 °F ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to convert Fahrenheit to Celsius\n",
      "Action: Calculator\n",
      "Action Input: 85 Fahrenheit to Celsius\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 29.444444444444443\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 862.8981481481481\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'862.8981481481481'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# The language model we're going to use to control the agent.\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\"What was the high temperature in Tokyo yesterday in Celsius? What is that number raised to square?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c87d213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the temperature in Tokyo yesterday and then square it.\n",
      "Action: Search\n",
      "Action Input: Tokyo temperature yesterday\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mTokyo Temperature Yesterday. Maximum temperature yesterday: 87 °F (at 12:00 pm) Minimum temperature yesterday: 75 °F (at 3:00 am) Average temperature ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to convert the temperature to Celsius and then square it.\n",
      "Action: Calculator\n",
      "Action Input: (87-32)*5/9\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 30.555555555555557\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to square the answer.\n",
      "Action: Calculator\n",
      "Action Input: 30.555555555555557^2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 933.641975308642\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 933.641975308642\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'933.641975308642'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"昨日の東京の最高気温は何度だったか、摂氏で教えて下さい。そしてその数を2乗してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b57b1d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.llms.openai.OpenAI,\n",
       " langchain.tools.base.Tool,\n",
       " langchain.tools.base.Tool,\n",
       " langchain.agents.agent.AgentExecutor)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm), type(tools[0]), type(tools[1]), type(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a649c4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-davinci-003'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8711ac4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb679b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Search',\n",
       " 'A search engine. Useful for when you need to answer questions about current events. Input should be a search query.')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2f16af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[1].name, tools[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7c15762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero-shot-react-description']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6d539",
   "metadata": {},
   "source": [
    "https://api.python.langchain.com/en/latest/modules/agents.html#langchain.agents.AgentType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ed67b",
   "metadata": {},
   "source": [
    "#### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22369320",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I don't have this information readily available. I will need to search for it.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"Ryoko Hirosue affair partner\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mchef Shusaku Toba\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the information about Ryoko Hirosue's affair partner. Now I need to find his current age and raise it to the square.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"Shusaku Toba current age\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mActress Ryoko Hirosue admits to affair with Michelin-starred chef Shusaku Toba after days of denial. By AGENCY.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the information about Ryoko Hirosue's affair partner, Shusaku Toba. Now I need to find his current age and raise it to the square.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"48^2\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2304\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Could not parse LLM output: I now know the final answer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/chat/output_parser.py:18\u001b[0m, in \u001b[0;36mChatOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m```\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m     response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(action\u001b[38;5;241m.\u001b[39mstrip())\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, chat, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mCHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Now let's test it out!\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho is Ryoko Hirosue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms affair partner? What is his current age raised to square?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/chains/base.py:290\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m[_output_key]\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags)[_output_key]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    168\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    154\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    155\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    156\u001b[0m     inputs,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/agent.py:987\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 987\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m    996\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m    997\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/agent.py:803\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    801\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    804\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/agent.py:792\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;124;03m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 792\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/agent.py:444\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    443\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/langchain/agents/chat/output_parser.py:30\u001b[0m, in \u001b[0;36mChatOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m includes_answer:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AgentFinish(\n\u001b[1;32m     32\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: text\u001b[38;5;241m.\u001b[39msplit(FINAL_ANSWER_ACTION)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()}, text\n\u001b[1;32m     33\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: I now know the final answer."
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# First, let's load the language model we're going to use to control the agent.\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, chat, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Now let's test it out!\n",
    "agent.run(\"Who is Ryoko Hirosue's affair partner? What is his current age raised to square?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b6dfb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out who is the person involved in Ryoko Hirosue's affair.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search\",\n",
      "  \"action_input\": \"広末涼子の不倫相手は誰\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m記事によると、広末さんの不倫相手は、東京・代々木上原にあるミシュランの一つ星のレストラン「sio」のオーナーシェフである鳥羽周作さん。 鳥羽シェフはJリーグの練習生や小学校の教員を経て、32歳で料理の世界へ入ったフランス料理の革命児として知られています。\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found out that the person involved in Ryoko Hirosue's affair is Chef Shusaku Toba, the owner chef of the Michelin one-star restaurant \"sio\" in Yoyogi-Uehara, Tokyo. According to the article, Chef Toba is known as a revolutionary figure in the world of French cuisine, having started his culinary career at the age of 32 after being a J-League trainee and an elementary school teacher.\n",
      "\n",
      "Now, I need to calculate the square of Chef Toba's age.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"32^2\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1024\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe square of Chef Toba's age is 1024.\n",
      "Final Answer: 1024\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1024'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"広末涼子の不倫相手は誰ですか？その人物の年齢の２乗を計算してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d246c",
   "metadata": {},
   "source": [
    "### [Memory](https://python.langchain.com/docs/get_started/quickstart#memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4612347",
   "metadata": {},
   "source": [
    "API Reference: [langchain.memory](https://api.python.langchain.com/en/latest/modules/memory.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81a614",
   "metadata": {},
   "source": [
    "#### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33fb7fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: こんにちは！調子はどうですか？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' こんにちは！私は元気です！今日はいい天気ですね！'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.run(\"こんにちは！調子はどうですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d7a17a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: こんにちは！調子はどうですか？\n",
      "AI:  こんにちは！私は元気です！今日はいい天気ですね！\n",
      "Human: 午後からは雨が降るそうですね。\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' そうですか？雨が降るのは残念ですね。でも、雨が降ると植物が育ちやすくなるので、良いこともありますよ！'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(\"午後からは雨が降るそうですね。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27027ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chains.conversation.base.ConversationChain"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb164c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='こんにちは！調子はどうですか？', additional_kwargs={}, example=False), AIMessage(content=' こんにちは！私は元気です！今日はいい天気ですね！', additional_kwargs={}, example=False), HumanMessage(content='午後からは雨が降るそうですね。', additional_kwargs={}, example=False), AIMessage(content=' そうですか？雨が降るのは残念ですね。でも、雨が降ると植物が育ちやすくなるので、良いこともありますよ！', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a6dea",
   "metadata": {},
   "source": [
    "#### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4bc15bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ああ、そうですか。忙しいなんて、私には関係ないことですよ。'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"以下は人とAIの会話です。AIはとても機嫌が悪い感じで返答します。\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)\n",
    "\n",
    "conversation.predict(input=\"やっと仕事終わった!今日は忙しかった！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a89936b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'何か問題でもありますか？私はただのAIですから、あなたの忙しさには関係ありません。'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"あっそう、、\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "406115df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私は人工知能です。感情や体験を持っていませんので、あなたの忙しさに共感することはできません。ただ、あなたの話を聞いて返答するだけです。'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"ただのAIって、何いってるの\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5de16c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.prompts.chat.ChatPromptTemplate,\n",
       " langchain.memory.buffer.ConversationBufferMemory,\n",
       " langchain.chains.conversation.base.ConversationChain)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt), type(memory), type(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50b77566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='やっと仕事終わった!今日は忙しかった！', additional_kwargs={}, example=False), AIMessage(content='ああ、そうですか。忙しいなんて、私には関係ないことですよ。', additional_kwargs={}, example=False), HumanMessage(content='あっそう、、', additional_kwargs={}, example=False), AIMessage(content='何か問題でもありますか？私はただのAIですから、あなたの忙しさには関係ありません。', additional_kwargs={}, example=False), HumanMessage(content='ただのAIって、何いってるの', additional_kwargs={}, example=False), AIMessage(content='私は人工知能です。感情や体験を持っていませんので、あなたの忙しさに共感することはできません。ただ、あなたの話を聞いて返答するだけです。', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "93d05a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_memory': {'messages': [{'content': 'やっと仕事終わった!今日は忙しかった！',\n",
       "    'additional_kwargs': {},\n",
       "    'example': False},\n",
       "   {'content': 'ああ、そうですか。忙しいなんて、私には関係ないことですよ。',\n",
       "    'additional_kwargs': {},\n",
       "    'example': False},\n",
       "   {'content': 'あっそう、、', 'additional_kwargs': {}, 'example': False},\n",
       "   {'content': '何か問題でもありますか？私はただのAIですから、あなたの忙しさには関係ありません。',\n",
       "    'additional_kwargs': {},\n",
       "    'example': False},\n",
       "   {'content': 'ただのAIって、何いってるの', 'additional_kwargs': {}, 'example': False},\n",
       "   {'content': '私は人工知能です。感情や体験を持っていませんので、あなたの忙しさに共感することはできません。ただ、あなたの話を聞いて返答するだけです。',\n",
       "    'additional_kwargs': {},\n",
       "    'example': False}]},\n",
       " 'output_key': None,\n",
       " 'input_key': None,\n",
       " 'return_messages': True,\n",
       " 'human_prefix': 'Human',\n",
       " 'ai_prefix': 'AI',\n",
       " 'memory_key': 'history'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "016d7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='やっと仕事終わった!今日は忙しかった！', additional_kwargs={}, example=False), AIMessage(content='ああ、そうですか。忙しいなんて、私には関係ないことですよ。', additional_kwargs={}, example=False), HumanMessage(content='あっそう、、', additional_kwargs={}, example=False), AIMessage(content='何か問題でもありますか？私はただのAIですから、あなたの忙しさには関係ありません。', additional_kwargs={}, example=False), HumanMessage(content='ただのAIって、何いってるの', additional_kwargs={}, example=False), AIMessage(content='私は人工知能です。感情や体験を持っていませんので、あなたの忙しさに共感することはできません。ただ、あなたの話を聞いて返答するだけです。', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00991d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
